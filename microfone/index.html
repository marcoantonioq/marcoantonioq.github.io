<!DOCTYPE html>
<html lang="pt-BR">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Reconhecimento de fala</title>
  <style>
    /* Melhoria de estiliza√ß√£o e acessibilidade */
    :root {
      --bg: #f7f9fc;
      --card: #ffffff;
      --accent: #0b63d1;
      --danger: #c92a2a;
      --danger-dark: #7a0000;
      --success: #0b8a3e;
      --muted: #6b7280;
      --radius: 10px;
      --gap: 12px;
    }

    body {
      background: var(--bg);
      color: #0b1220;
    }

    #app {
      max-width: 900px;
      margin: 24px auto;
      padding: 20px;
      background: var(--card);
      border-radius: var(--radius);
      box-shadow: 0 6px 18px rgba(11, 17, 32, 0.06);
    }

    header.app-header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 16px;
      margin-bottom: 14px;
    }

    header.app-header h1 {
      font-size: 1.25rem;
      margin: 0;
    }

    header.app-header p.subtitle {
      margin: 0;
      color: var(--muted);
      font-size: 0.95rem;
    }

    .controls {
      display: flex;
      flex-wrap: wrap;
      gap: var(--gap);
      align-items: center;
      margin-bottom: 16px;
    }

    fieldset.controls-panel {
      display: flex;
      gap: var(--gap);
      align-items: center;
      border: 1px solid #e6edf8;
      padding: 12px;
      border-radius: 8px;
      background: linear-gradient(180deg, rgba(11, 99, 209, 0.03), transparent);
    }

    fieldset.controls-panel legend {
      font-weight: 600;
      margin-left: 8px;
      color: var(--muted);
      padding: 0 6px;
    }

    .primary-btn {
      background: var(--accent);
      min-width: 160px;
      padding: 12px 18px;
      border-radius: 8px;
      box-shadow: none;
      font-weight: 700;
      border: none;
      color: #fff;
      cursor: pointer;
    }

    .primary-btn[aria-pressed="true"] {
      background: #063f87;
    }

    .danger-btn {
      background: var(--danger);
      min-width: 140px;
      color: #fff;
      border-radius: 8px;
      padding: 10px 14px;
    }

    .success-btn {
      background: var(--success);
      min-width: 140px;
      color: #fff;
      border-radius: 8px;
      padding: 10px 14px;
    }

    select,
    input[type="file"] {
      padding: 8px 10px;
      border-radius: 6px;
      border: 1px solid #cbd5e1;
      background: #fff;
      font-size: 0.95rem;
    }

    .control-group {
      display: flex;
      gap: 8px;
      align-items: center;
    }

    #transcribedText {
      margin: 12px 0;
      padding: 12px;
      background: #f1f5f9;
      border-radius: 8px;
      min-height: 48px;
      font-size: 1rem;
    }

    #transcriptHistory {
      list-style: none;
      padding: 0;
      margin: 8px 0 0 0;
      max-height: 240px;
      overflow: auto;
      border-top: 1px solid #eef2f7;
      padding-top: 10px;
    }

    #transcriptHistory li {
      padding: 8px;
      border-radius: 6px;
      margin-bottom: 6px;
      background: #ffffff;
      box-shadow: 0 1px 0 rgba(15, 23, 42, 0.02);
      display: flex;
      gap: 8px;
      align-items: flex-start;
    }

    #transcriptHistory small {
      color: var(--muted);
      min-width: 64px;
      text-align: left;
      font-variant-numeric: tabular-nums;
    }

    /* focus accessibility */
    button:focus,
    select:focus,
    input[type="file"]:focus {
      outline: 3px solid rgba(11, 99, 209, 0.18);
      outline-offset: 2px;
    }

    .visually-hidden {
      position: absolute !important;
      height: 1px;
      width: 1px;
      overflow: hidden;
      clip: rect(1px, 1px, 1px, 1px);
      white-space: nowrap;
      border: 0;
      padding: 0;
      margin: -1px;
    }

    @media (max-width: 600px) {
      .controls {
        flex-direction: column;
        align-items: stretch;
      }

      fieldset.controls-panel {
        flex-direction: column;
        align-items: stretch;
      }

      .primary-btn,
      .danger-btn,
      .success-btn {
        width: 100%;
        min-width: unset;
      }
    }
  </style>
</head>

<body>
  <div id="app" v-cloak>
    <header class="app-header" aria-hidden="false">
      <div>
        <h1>Reconhecimento de fala</h1>
        <p class="subtitle">Escolha microfone, inicie a grava√ß√£o e veja a transcri√ß√£o em tempo real.</p>
      </div>
      <div class="control-status" aria-live="polite" aria-atomic="true">
        <span class="visually-hidden" id="statusLabel">Status da aplica√ß√£o</span>
        <strong aria-describedby="statusLabel" style="color:var(--muted);font-size:0.95rem;">
          {{ recording ? 'Gravando' : 'Parado' }}
        </strong>
      </div>
    </header>

    <div class="controls">
      <fieldset class="controls-panel" role="group" aria-label="Controles de grava√ß√£o">
        <legend>Controles</legend>

        <div class="control-group">
          <button class="primary-btn" v-on:click="toggleRecording" :aria-pressed="recording.toString()" aria-label="Iniciar ou parar grava√ß√£o">
            {{ recording ? '‚èπ Parar' : 'üéô Iniciar' }}
          </button>
        </div>

        <div class="control-group">
          <button class="success-btn" v-on:click="downloadConversation" aria-label="Baixar conversas">‚¨áÔ∏è Baixar</button>
        </div>

        <div class="control-group">
          <button class="danger-btn" v-on:click="clearConversation" aria-label="Apagar conversas">üóë Apagar</button>
        </div>

        <div style="flex:1;"></div>

        <div class="control-group" style="align-items:center;">
          <label for="fileInput" class="visually-hidden">Selecionar arquivo de √°udio ou v√≠deo</label>
          <input id="fileInput" type="file" accept="audio/*,video/*" v-on:change="selectAudioFile" />
        </div>

      </fieldset>
    </div>

    <div class="controls" style="margin-top:6px;">
      <label for="micSelect" style="font-weight:600;color:var(--muted);margin-right:8px;">Microfone</label>
      <select id="micSelect" v-model="selectedDeviceId" aria-label="Selecionar microfone">
        <option value="">Padr√£o do sistema</option>
        <option v-for="device in audioDevices" :key="device.deviceId" :value="device.deviceId">
          {{ device.label || ('Microfone ' + device.deviceId) }}
        </option>
      </select>
      <button style="padding:8px 10px;border-radius:6px;" v-on:click="enumerateAudioDevices" aria-label="Atualizar lista de microfones">‚ü≥ Atualizar</button>
    </div>

    <!-- √°rea de transcri√ß√£o com aria-live para leitores de tela -->
    <section aria-label="Transcri√ß√£o" aria-live="polite" aria-atomic="true">
      <p id="transcribedText" role="status">{{ currentTranscript || 'Sem transcri√ß√£o ainda' }}</p>
    </section>

    <section aria-label="Hist√≥rico de transcri√ß√µes">
      <h2 class="visually-hidden">Hist√≥rico</h2>
      <ul id="transcriptHistory" role="list" aria-label="Lista de transcri√ß√µes">
        <li v-for="([time, transcript], id) in transcriptHistory" :key="id">
          <small aria-hidden="true">{{ time.replace(/:\d\d$/, '') }}</small>
          <div style="flex:1;">
            <span class="visually-hidden">Transcri√ß√£o √†s </span>
            <span>{{ transcript }}</span>
          </div>
        </li>
      </ul>
    </section>

  </div>

  <!-- Substituir os scripts externos por scripts inline -->
  <!-- Cole aqui o conte√∫do completo de vosk.js (opcional) -->
  <script>
    // === VOSK.JS START ===
    // Cole o conte√∫do inteiro de vosk.js abaixo deste coment√°rio (ou mantenha vazio se j√° o incorporou).
    // === VOSK.JS END ===
  </script>

  <!-- Removido placeholder Vue.js; agora carregamos dinamicamente se necess√°rio e inicializamos a app -->
  <script>
    // Carrega Vue dinamicamente se n√£o estiver presente
    function ensureVue() {
      if (window.Vue) return Promise.resolve();
      return new Promise((resolve, reject) => {
        const s = document.createElement('script');
        // vers√£o de production do Vue 3 (global build)
        s.src = 'https://unpkg.com/vue@3/dist/vue.global.prod.js';
        s.onload = () => resolve();
        s.onerror = (e) => reject(new Error('Falha ao carregar Vue: ' + e));
        document.head.appendChild(s);
      });
    }

    // Inicializa a aplica√ß√£o (conte√∫do movido para dentro da fun√ß√£o)
    async function initApp() {
      const VOSK_MODEL_PATH = "vosk-model-small-pt-0.3"; // coloque o modelo nesta pasta

      const app = Vue.createApp({
        data() {
          return {
            recording: false,
            currentTranscript: "",
            transcriptHistory:
              JSON.parse(localStorage.getItem("transcriptHistory")) || [],
            recognition: null,
            audioSource: null,
            audioFile: null,
            voskReady: false,
            voskRecognizer: null,
            voskModel: null,
            voskSampleRate: 16000,
            voskWorker: null,
            useVosk: false,

            // Novas props para sele√ß√£o de microfone
            audioDevices: [],
            selectedDeviceId: "",
            audioStream: null,
          };
        },
        mounted() {
          if ("webkitSpeechRecognition" in window) {
            this.recognition = new webkitSpeechRecognition();
            this.recognition.continuous = true;
            this.recognition.interimResults = true;
            this.recognition.language = "pt-BR";
            this.recognition.onresult = (event) => {
              let transcript = "";
              let final = "";
              for (let i = event.resultIndex; i < event.results.length; i++) {
                const result = event.results[i][0];
                if (event.results[i].isFinal) {
                  final += result.transcript;
                } else {
                  transcript += result.transcript;
                }
              }
              this.currentTranscript = transcript;
              if (final.trim() !== "") {
                this.transcriptHistory.unshift([
                  new Date().toLocaleString().split(", ")[1],
                  final.trim(),
                ]);
                this.saveTranscriptHistory();
              }
            };
            this.recognition.onend = () => {
              if (this.recording) {
                this.recognition.start();
              }
            };
          } else {
            // Inicializa Vosk se n√£o houver suporte nativo
            this.initVosk();
            this.useVosk = true;
          }
          // Tenta popular a lista de microfones ao iniciar
          this.enumerateAudioDevices();
        },
        methods: {
          async initVosk() {
            if (window.Vosk) {
              this.currentTranscript = "Carregando modelo Vosk...";
              const model = await Vosk.createModel(VOSK_MODEL_PATH);
              this.voskModel = model;
              this.voskReady = true;
              this.currentTranscript = "";
            } else {
              this.currentTranscript = "Vosk n√£o carregado. Verifique vosk.js.";
            }
          },
          toggleRecording() {
            if (this.recording) {
              this.recording = false;
              if (this.recognition) {
                this.recognition.stop();
              }
              if (this.useVosk) {
                this.stopVoskMic();
              }
              this.currentTranscript = "";
            } else {
              this.recording = true;
              if (this.recognition) {
                this.recognition.start();
              } else if (this.useVosk) {
                this.startVoskMic();
              }
            }
          },
          async enumerateAudioDevices() {
            try {
              // Para obter labels, precisamos pedir permiss√£o primeiro
              let ok = false;
              try {
                const s = await navigator.mediaDevices.getUserMedia({ audio: true });
                s.getTracks().forEach(t => t.stop());
                ok = true;
              } catch (e) {
                // permiss√£o negada ou n√£o solicitada; ainda assim tentamos enumerar
              }
              const devices = await navigator.mediaDevices.enumerateDevices();
              this.audioDevices = devices.filter(d => d.kind === "audioinput");
              // se ainda n√£o houver selectedDeviceId, mant√©m vazio (padr√£o)
              if (!this.selectedDeviceId && this.audioDevices.length > 0 && ok) {
                // tenta escolher o primeiro por conveni√™ncia (opcional)
                this.selectedDeviceId = "";
              }
            } catch (err) {
              console.error("Erro ao listar dispositivos:", err);
            }
          },
          stopAudioStream() {
            if (this.audioStream) {
              this.audioStream.getTracks().forEach(t => t.stop());
              this.audioStream = null;
            }
          },
          async startVoskMic() {
            if (!this.voskReady) {
              this.currentTranscript = "Modelo Vosk n√£o carregado ainda.";
              return;
            }
            this.currentTranscript = "Fale agora...";
            // Para usar o microfone selecionado, aplica constraint deviceId
            const constraints = this.selectedDeviceId
              ? { audio: { deviceId: { exact: this.selectedDeviceId } } }
              : { audio: true };
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            // guarda stream para poder parar depois
            this.stopAudioStream();
            this.audioStream = stream;

            const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: this.voskSampleRate });
            const source = audioContext.createMediaStreamSource(stream);
            const processor = audioContext.createScriptProcessor(4096, 1, 1);
            source.connect(processor);
            processor.connect(audioContext.destination);

            const recognizer = await this.voskModel.createRecognizer(this.voskSampleRate);
            this.voskRecognizer = recognizer;

            processor.onaudioprocess = (e) => {
              if (!this.recording) return;
              const input = e.inputBuffer.getChannelData(0);
              recognizer.acceptWaveform(input);
              const result = recognizer.result();
              if (result && result.text) {
                this.currentTranscript = result.text;
                if (result.text.trim() !== "") {
                  this.transcriptHistory.unshift([
                    new Date().toLocaleString().split(", ")[1],
                    result.text.trim(),
                  ]);
                  this.saveTranscriptHistory();
                }
              }
            };

            this.voskStop = () => {
              processor.disconnect();
              source.disconnect();
              this.stopAudioStream();
              recognizer.free();
              audioContext.close();
            };
          },
          stopVoskMic() {
            if (this.voskStop) {
              this.voskStop();
              this.voskStop = null;
            }
          },
          async extractAudioFromVideo(file) {
            // Extrai √°udio de v√≠deo usando um elemento <video> e OfflineAudioContext
            return new Promise((resolve, reject) => {
              const url = URL.createObjectURL(file);
              const video = document.createElement("video");
              video.src = url;
              video.crossOrigin = "anonymous";
              video.muted = true;
              video.play();
              video.oncanplay = async () => {
                try {
                  const audioCtx = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(1, video.duration * 44100, 44100);
                  const source = audioCtx.createMediaElementSource(video);
                  source.connect(audioCtx.destination);
                  await audioCtx.startRendering();
                  audioCtx.oncomplete = (e) => {
                    const renderedBuffer = e.renderedBuffer;
                    // Usar this.encodeWAV (m√©todo do mesmo app) em vez de app.config.globalProperties
                    const wav = this.encodeWAV(renderedBuffer);
                    resolve(wav);
                    URL.revokeObjectURL(url);
                  };
                } catch (err) {
                  reject(err);
                }
              };
              video.onerror = reject;
            });
          },
          async selectAudioFile(event) {
            if (this.audioSource) {
              try {
                this.audioSource.stop();
              } catch (e) { }
              this.audioSource.disconnect && this.audioSource.disconnect();
              this.audioSource = null;
            }
            this.audioFile = event.target.files[0];
            if (this.audioFile) {
              // Extrai √°udio se for v√≠deo
              let file = this.audioFile;
              let audioBuffer;
              if (file.type.startsWith("video/")) {
                this.currentTranscript = "Extraindo √°udio do v√≠deo...";
                audioBuffer = await this.extractAudioFromVideo(file);
              } else {
                const arrayBuffer = await file.arrayBuffer();
                audioBuffer = arrayBuffer;
              }
              if (this.recognition) {
                // N√£o h√° suporte nativo para transcri√ß√£o de arquivos, use Vosk
                this.currentTranscript = "Reconhecimento nativo n√£o suporta arquivos. Usando Vosk.";
                if (!this.voskReady) await this.initVosk();
                await this.transcribeWithVosk(audioBuffer);
              } else if (this.useVosk) {
                await this.transcribeWithVosk(audioBuffer);
              }
            }
          },
          async transcribeWithVosk(arrayBuffer) {
            if (!this.voskReady) {
              this.currentTranscript = "Modelo Vosk n√£o carregado ainda.";
              return;
            }
            this.currentTranscript = "Transcrevendo...";
            // Decodifica o √°udio para PCM float32
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: this.voskSampleRate });
            const decoded = await audioCtx.decodeAudioData(arrayBuffer.slice(0));
            const channelData = decoded.getChannelData(0);
            const recognizer = await this.voskModel.createRecognizer(this.voskSampleRate);
            recognizer.acceptWaveform(channelData);
            const result = recognizer.finalResult();
            if (result && result.text) {
              this.currentTranscript = result.text;
              if (result.text.trim() !== "") {
                this.transcriptHistory.unshift([
                  new Date().toLocaleString().split(", ")[1],
                  result.text.trim(),
                ]);
                this.saveTranscriptHistory();
              }
            } else {
              this.currentTranscript = "Nenhum texto reconhecido.";
            }
            recognizer.free();
            audioCtx.close();
          },
          downloadConversation() {
            if (this.transcriptHistory.length > 0) {
              const lines = this.transcriptHistory.map(
                ([time, transcript]) => `[${time}] ${transcript}`
              );
              const blob = new Blob([lines.join("\n")], {
                type: "text/plain",
              });
              const url = URL.createObjectURL(blob);
              const a = document.createElement("a");
              a.href = url;
              a.download = "conversation_history.txt";
              document.body.appendChild(a);
              a.click();
              document.body.removeChild(a);
              URL.revokeObjectURL(url);
            }
          },
          clearConversation() {
            this.transcriptHistory = [];
            this.saveTranscriptHistory();
          },
          saveTranscriptHistory() {
            localStorage.setItem(
              "transcriptHistory",
              JSON.stringify(this.transcriptHistory)
            );
          },
          // Utilit√°rio para codificar WAV (caso precise)
          encodeWAV(buffer) {
            // ...implemente se necess√°rio...
          }
        },
      });

      app.mount("#app");
    }

    // Garantir Vue e ent√£o iniciar a app
    ensureVue()
      .then(() => initApp())
      .catch((err) => {
        console.error(err);
        const el = document.getElementById('transcribedText');
        if (el) el.textContent = "Erro ao carregar depend√™ncias: " + err.message;
      });
  </script>

</body>
</html>